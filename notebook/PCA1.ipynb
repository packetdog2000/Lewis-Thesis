{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import colorConverter\n",
    "import gmplot\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, Birch, MiniBatchKMeans,DBSCAN\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.spatial.distance import cdist,pdist\n",
    "from geopy.distance import great_circle\n",
    "from shapely.geometry import MultiPoint\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"output\"\n",
    "## july-oct-raw2-train.csv\n",
    "# csv_file = \"july-oct-batch2-train.csv\" ## raw_input(\"Enter csv file to load:\")\n",
    "# csv_file = \"batch2-train.csv\" ## raw_input(\"Enter csv file to load:\")\n",
    "csv_file = \"july-oct-batch3-train.csv\" ## raw_input(\"Enter csv file to load:\")\n",
    "file_str = \"%s/%s\" %(OUTPUT_FOLDER, csv_file)\n",
    "a = pd.read_csv(file_str) \n",
    "a.columns = ['index1', 'address','city', 'day','hour','type','latitude','longitude','parent_incident','state']\n",
    "a.drop('index1',axis=1,inplace=True)\n",
    "a.describe()\n",
    "X = a[['address','city', 'day','hour','type','latitude','longitude','parent_incident','state']] ## MODEL 1\n",
    "# X = a[['address', 'day','hour','type','parent_incident','latitude','longitude']] ## MODEL 2\n",
    "# X = a[['address', 'day','hour','type','parent_incident','latitude','longitude']] ## MODEL 2\n",
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "pca_2d = pd.DataFrame(pca.transform(X))\n",
    "\n",
    "# Add PCA cols to DF\n",
    "X['pca1'] = pca_2d[0]\n",
    "X['pca2'] = pca_2d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# fig, (ax1) = plt.subplots(1)\n",
    "# fig.set_size_inches(16, 6)\n",
    "# ax1.scatter(X['pca1'],X['pca2'],c=X['type'],s=5,alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-MEANS LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ari_list = np.array([])\n",
    "\n",
    "x_axis = np.arange(2,4,1)\n",
    "for i in x_axis:\n",
    "    ## RUN K-MEANS\n",
    "    km = KMeans(n_clusters=i, init='k-means++').fit(pca_2d)\n",
    "    km_pred = KMeans(n_clusters=10, init='k-means++').fit_predict(pca_2d)\n",
    "    labels = km.labels_\n",
    "    clust_centers = km.cluster_centers_\n",
    "    ## GET ARI \n",
    "    ari = metrics.adjusted_rand_score(km.labels_, km_pred) \n",
    "    ari_list = np.append(ari_list, ari)\n",
    "    sil = metrics.silhouette_score(pca_2d, km_pred)\n",
    "    ## PLOT\n",
    "    title_str = \"K-Means, Clusters=%s, ARI=%.3f, Silhouette Coefficient=%.3f\" %(i,ari,sil)\n",
    "    fig, (ax1) = plt.subplots(1)\n",
    "    fig.set_size_inches(12, 4)\n",
    "    points = ax1.scatter(pca_2d[0],pca_2d[1],c=labels,s=5, alpha=0.6)\n",
    "    centroids = ax1.scatter(clust_centers[:,1],clust_centers[:,0], marker='o',s=75, edgecolors='w')\n",
    "    ax1.legend([points,centroids],['Points','Centroids'])\n",
    "    ax1.set_title(title_str)\n",
    "    ax1.set_ylabel(\"PCA 1\")\n",
    "    ax1.set_xlabel(\"PCA 2\")\n",
    "\n",
    "# for i in x_axis:\n",
    "fig, (ax2) = plt.subplots(1)\n",
    "fig.set_size_inches(16, 6)  \n",
    "ari_score = ax2.scatter(x_axis,ari_list,c='r',s=40)\n",
    "ax2.plot(x_axis,ari_list,c='b')\n",
    "ax2.legend([ari_score],['Adjusted Rand Score'])\n",
    "ax2.set_title(\"Adjusted Rand Index for K-Means\")\n",
    "ax2.set_ylabel(\"Adjusted Rand Score\")\n",
    "ax2.set_xlabel(\"Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.28425115,  0.35885024],\n",
       "       [ 1.28696969,  1.39095928],\n",
       "       [ 0.31068367, -0.84364178]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLUSTER_NUMBER = 3\n",
    "km = KMeans(n_clusters=CLUSTER_NUMBER, init='k-means++').fit(pca_2d)\n",
    "km_pred = KMeans(n_clusters=10, init='k-means++').fit_predict(pca_2d)\n",
    "labels = km.labels_\n",
    "clust_centers = km.cluster_centers_\n",
    "# print len(labels)\n",
    "clust_centers\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwingarcia/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/edwingarcia/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/edwingarcia/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "raw_map_df = pd.read_csv(\"output/july-oct-raw.csv\")\n",
    "a_centroids = pd.DataFrame([])\n",
    "gmap_centroids = pd.DataFrame([])\n",
    "for i in clust_centers:\n",
    "    closest, y = pairwise_distances_argmin_min(i, pca_2d)\n",
    "    a_centroids = a_centroids.append(a.ix[closest[0]])\n",
    "    gmap_centroids = a_centroids.append(raw_map_df.ix[closest[0]])\n",
    "    \n",
    "plt.scatter(a['longitude'],a['latitude'],c=a['klabel'],s=3,alpha=0.5)\n",
    "plt.scatter(a_centroids['longitude'],a_centroids['latitude'],c='r',s=150, marker='o',edgecolors='w', alpha=0.8)\n",
    "\n",
    "## GENERATE GOOGLE MAP IN SEPARATE HTML FILE\n",
    "\n",
    "\n",
    "\n",
    "gmap = gmplot.GoogleMapPlotter(29.8, -95.4, 9.0)\n",
    "gmap.scatter(raw_map_df['latitude'], raw_map_df['longitude'], '#3B0B39', alpha=0.4, size=60, marker=False)\n",
    "gmap.heatmap(gmap_centroids['latitude'], gmap_centroids['longitude'],radius=(20))\n",
    "\n",
    "## PATH IS OUTPUT FOLDER/FILENAME + SEQUENCE NUMBER.html\n",
    "map_file = \"%s/%s-%s.html\" %(OUTPUT_FOLDER,\"KMEANS\",CLUSTER_NUMBER)\n",
    "gmap.draw(map_file)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIRCH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## BIRCH CLUSTERING TOOL\n",
    "x_axis = np.arange(0.3,0.9,0.1)\n",
    "\n",
    "for i in x_axis:\n",
    "    ## LOOP OVER THRESHOLD\n",
    "    brc = Birch(branching_factor = 50, n_clusters = 3, threshold = i, compute_labels = True)\n",
    "    brc.fit(pca_2d)\n",
    "    \n",
    "\n",
    "    labels = brc.labels_\n",
    "    pred_labels = brc.predict(pca_2d)\n",
    "    centroids = brc.subcluster_centers_\n",
    "    centroids_size = len(centroids)\n",
    "    \n",
    "\n",
    "\n",
    "    fig, (ax1)= plt.subplots(1, figsize=(16,8))\n",
    "    points = ax1.scatter(pca_2d[0],pca_2d[1],c=labels,s=5, alpha=0.6)\n",
    "    centroids = ax1.scatter(centroids[:,0],centroids[:,1],marker='^',s=75)\n",
    "    title_str = \"BIRCH, Threshold=%s, Centroids = %s\" %(i,centroids_size)\n",
    "    ax1.legend([points,centroids],['Points','Centroids'])\n",
    "    ax1.set_title(title_str)\n",
    "    ax1.set_ylabel(\"PCA 1\")\n",
    "    ax1.set_xlabel(\"PCA 2\")\n",
    "    \n",
    "\n",
    "plt.show()\n",
    "# print len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MINIBATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cluster_nums = int(raw_input(\"Number of clusters: \"))\n",
    "batch_size = int(raw_input(\"Batch size (default 100): \"))\n",
    "ari_list = np.array([])\n",
    "x_axis = np.arange(2,5,1)\n",
    "\n",
    "for i in x_axis:\n",
    "    mbk = MiniBatchKMeans(init='k-means++', n_clusters=i, batch_size=batch_size)\n",
    "\n",
    "    mbk.fit(pca_2d)\n",
    "    mbk_pred = mbk.fit_predict(pca_2d)\n",
    "    clust_centers = mbk.cluster_centers_\n",
    "    labels = mbk.labels_\n",
    "    \n",
    "    ## GET ARI\n",
    "    ari = metrics.adjusted_rand_score(labels, mbk_pred) \n",
    "    ari_list = np.append(ari_list, ari)\n",
    "    print ari, labels,mbk_pred\n",
    "    \n",
    "\n",
    "    fig, (ax1)= plt.subplots(1, figsize=(16,8))\n",
    "    points = ax1.scatter(pca_2d[0],pca_2d[1],c=labels,s=5, alpha=0.6)\n",
    "    centroids = ax1.scatter(clust_centers[:,0],clust_centers[:,1],marker='o', edgecolors='w', s=75)\n",
    "    title_str = \"MiniBatch K-Means, Batch Size=%s, Clusters = %s\" %(batch_size,i)\n",
    "    ax1.set_title(title_str)\n",
    "    ax1.legend([points,centroids],['Points','Centroids'])\n",
    "    ax1.set_ylabel(\"PCA 1\")\n",
    "    ax1.set_xlabel(\"PCA 2\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps: 0.09 , min_samples: 18 , Clusters:  19 , Clustered Points: 8705\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.08\n",
    "min_samples=10\n",
    "\n",
    "eps_list = np.arange(.09,.1,0.02)\n",
    "min_samples_list = np.arange(18,20,3)\n",
    "for i in eps_list:\n",
    "    \n",
    "    for j in min_samples_list:\n",
    "        db = DBSCAN(eps=i, min_samples=j).fit(pca_2d)\n",
    "        labels = db.labels_\n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        col_set = pd.Series(list(set(labels)))\n",
    "        clusters = pd.DataFrame([])\n",
    "        for k in db.core_sample_indices_:\n",
    "        #     print X.loc[i]\n",
    "            if k > -1:\n",
    "                clusters = clusters.append(X.loc[k])\n",
    "                \n",
    "        # Black removed and is used for noise instead.\n",
    "        unique_labels = set(labels)\n",
    "        colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))       \n",
    "        \n",
    "        fig, (ax1,ax2)= plt.subplots(1,2, figsize=(16,6))\n",
    "        percent_clustered = len(clusters)/float(len(labels)) * 100\n",
    "        \n",
    "        points = ax1.scatter(pca_2d[0],pca_2d[1],c=colors,s=5, marker='.', alpha=0.4)\n",
    "        points = ax2.scatter(pca_2d[0],pca_2d[1],c=labels,s=20, marker='.', alpha=0.4)\n",
    "        centroids = ax2.scatter(clusters['pca1'],clusters['pca2'], c=colors, marker='o',s=10, alpha=0.7)\n",
    "        \n",
    "        title_str = \"DBSCAN, Epsilon=%s, min_samples=%s\\nClusters=%s, Clustered points=%.2f\" %(i,j,n_clusters_,percent_clustered)\n",
    "        ax1.legend([points,centroids],['Points','Clusters'])\n",
    "        ax1.set_title(title_str)\n",
    "        ax1.set_ylabel(\"PCA 1\")\n",
    "        ax1.set_xlabel(\"PCA 2\")\n",
    "        \n",
    "        title_str2 = \"DBSCAN, Epsilon=%s, min_samples=%s\\nClusters=%s, Clustered points=%.2f%%\" %(i,j,n_clusters_,percent_clustered)\n",
    "        ax2.legend([points,centroids],['Points','Clusters'])\n",
    "        ax2.set_title(title_str2)\n",
    "        ax2.set_ylabel(\"PCA 1\")\n",
    "        ax2.set_xlabel(\"PCA 2\")\n",
    "        print \"eps:\",i,\", min_samples:\",j,\", Clusters: \",n_clusters_,\", Clustered Points:\", len(clusters)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = 'k'\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIAGNOSTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elbow Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter starting K: 2\n",
      "Enter ending K: 10\n",
      "[ 11927.41456607  21367.59518396  24295.74548767  26342.28404651\n",
      "  27954.37065979  28819.34007813  29577.05531618  30133.20817567\n",
      "  30680.53037466]\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib \n",
    "\n",
    "\n",
    "def plot_variance(start_,end_,interval_=1):\n",
    "    plt.subplots(figsize=(12,5))\n",
    "    \n",
    "#     X = X.as_matrix()\n",
    "    k_list = np.arange(start_,end_+1,interval_)\n",
    "\n",
    "    k_var = [KMeans(n_clusters=k).fit(pca_2d) for k in k_list]\n",
    "\n",
    "    centroids = [c.cluster_centers_ for c in k_var]\n",
    "\n",
    "    k_euclidian = [cdist(pca_2d, cent, 'euclidean') for cent in centroids]\n",
    "    dist = [np.min(ke, axis=1) for ke in k_euclidian]\n",
    "\n",
    "    ## Total Within cluster SS\n",
    "    wcss = [sum(d**2) for d in dist]\n",
    "    \n",
    "    ## Total SS\n",
    "    tss = sum(pdist(pca_2d)**2) / pca_2d.shape[0]\n",
    "\n",
    "    ## Between cluster SS\n",
    "    bss = tss - wcss    \n",
    "    print bss \n",
    "    plt.title(\"KMeans Explained Variance\")\n",
    "    plt.plot(k_list,bss)\n",
    "    points = plt.scatter(k_list,bss,c='r', s=25)\n",
    "    plt.ylabel('Variance')\n",
    "    plt.xlabel('K-value')\n",
    "   \n",
    "    plt.grid('on', which='major', axis='x' )\n",
    "    plt.grid('on', which='major', axis='y' )\n",
    "   \n",
    "    plt.legend([points],['Variance'])  \n",
    "    plt.xticks(k_list)\n",
    "\n",
    "start_k = int(raw_input(\"Enter starting K: \"))\n",
    "end_k = int(raw_input(\"Enter ending K: \"))\n",
    "\n",
    "plot_variance(start_k, end_k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
